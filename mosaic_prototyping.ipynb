{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d116b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fd9bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /Users/joe/Pictures/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29542ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "A.Affine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6956bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\"source\":\"/Users/joe/Pictures/G0040113.JPG\", \"boxes\":[[600, 212, 775, 300], [330, 390, 420, 440]],\n",
    "    \"class\":[\"hov_sign\", \"sticker\"]},\n",
    "    {\"source\":\"/Users/joe/Pictures/G0061823.JPG\", \"boxes\":[[620, 320, 680, 460], [160, 460, 230, 520]],\n",
    "    \"class\":[\"masonic_thing\", \"car\"]}\n",
    "]\n",
    "\n",
    "for i in range(len(data)):\n",
    "    for j in range(2):\n",
    "        b = data[i][\"boxes\"][j]\n",
    "        data[i][\"boxes\"][j] = [4*k for k in b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d493d8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfmlist = [\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.Affine(shear=(-20,20), rotate=(-20,20), p=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8551c2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose(tfmlist, bbox_params=A.BboxParams(format='pascal_voc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2523f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _augment(image, boxes, tfm=None):\n",
    "    \"\"\"\n",
    "    :image: PIL image\n",
    "    :boxes: list of lists; boxes in [left top right bottom] format\n",
    "    :tfm: Albumentations transform\n",
    "    \"\"\"\n",
    "    if tfm is None:\n",
    "        return image, boxes\n",
    "    transformed = tfm(image=np.array(image), bboxes=[x+[\"\"] for x in boxes])\n",
    "    return Image.fromarray(transformed[\"image\"]), [x[:4] for x in transformed[\"bboxes\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27001c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = Image.open(data[1][\"source\"])\n",
    "#i,b = _augment(img, data[1][\"boxes\"], tfm=transform)\n",
    "#i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725dfde1",
   "metadata": {},
   "source": [
    "to do:\n",
    "\n",
    "* random rescaling\n",
    "* albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfcdb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _area(b):\n",
    "    return (b[2]-b[0])*(b[3]-b[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7969fd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _crop_boxes(boxes, crop_box, classes, area_thresh=0.5):\n",
    "    \"\"\"\n",
    "    TO DO: implement an area check to see how much of each box is inside \n",
    "    the crop\n",
    "    \"\"\"\n",
    "    w_offset = crop_box[0]\n",
    "    h_offset = crop_box[1]\n",
    "    w = crop_box[2] - crop_box[0]\n",
    "    h = crop_box[3] - crop_box[1]\n",
    "    shifted_boxes = [[int(b[0]-w_offset), int(b[1]-h_offset), \n",
    "             int(b[2]-w_offset), int(b[3]-h_offset)] for b in boxes]\n",
    "    # clip boxes to outside of crop area\n",
    "    clipped_boxes = [[min(max(0, b[0]), w),\n",
    "                      min(max(0, b[1]), h),\n",
    "                      min(max(0, b[2]), w),\n",
    "                      min(max(0, b[3]), h)\n",
    "    ] for b in shifted_boxes]\n",
    "    # only keep boxes/labels if they meet the area thresh after clipping\n",
    "    outboxes = []\n",
    "    outlabels = []\n",
    "    for s, c, l in zip(boxes, clipped_boxes, classes):\n",
    "        if _area(c)/_area(s) >= area_thresh:\n",
    "            outboxes.append(c)\n",
    "            outlabels.append(l)\n",
    "    \n",
    "    return outboxes, outlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9867be27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _random_crop(source, boxes=[], classes=[], resize_to=(1000, 750), cropsize=(200,150), \n",
    "                 rand_scale=None, tfm=None):\n",
    "    \"\"\"\n",
    "    uniform random crop\n",
    "    \"\"\"\n",
    "    # load image\n",
    "    img = Image.open(source)\n",
    "    if rand_scale is not None:\n",
    "        s = np.random.uniform(rand_scale[0], rand_scale[1])\n",
    "        if resize_to is None:\n",
    "            resize_to = img.size\n",
    "        resize_to = (int(resize_to[0]/s), int(resize_to[1]/s))\n",
    "    # augment if albumentation object was passed\n",
    "    img, boxes = _augment(img, boxes, tfm)\n",
    "    \n",
    "    w,h = img.size\n",
    "    w_ratio = resize_to[0]/w\n",
    "    h_ratio = resize_to[1]/h\n",
    "    # resize image and rescale boxes\n",
    "    if resize_to is not None:\n",
    "        img = img.resize((resize_to[0],resize_to[1]))\n",
    "        boxes = [[int(b[0]*w_ratio), int(b[1]*h_ratio), int(b[2]*w_ratio), int(b[3]*h_ratio)] for b in boxes]\n",
    "    \n",
    "    # randomly choose an offset and turn into a bounding box\n",
    "    w_offset = np.random.randint(0, resize_to[0]-cropsize[0])\n",
    "    h_offset = np.random.randint(0, resize_to[1]-cropsize[1])\n",
    "    crop_box = [w_offset, h_offset, w_offset+cropsize[0], h_offset+cropsize[1]]\n",
    "    # crop image and boxes\n",
    "    img_c = img.crop(crop_box)\n",
    "    outboxes, outlabels = _crop_boxes(boxes, crop_box, classes)\n",
    "    return img_c, outboxes, outlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cb4449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _crop_around_random_box(source, boxes=[], classes=[], resize_to=(1000, 750), cropsize=(200,150), \n",
    "                            rand_scale=None, tfm=None):\n",
    "    \"\"\"\n",
    "    pick a box and crop around it. if no boxes, fall back to _random_crop\n",
    "    \"\"\"\n",
    "    # no boxes? just crop randomly\n",
    "    if len(boxes) == 0:\n",
    "        return _random_crop(source, boxes, classes, resize_to, cropsize, tfm=tfm)\n",
    "    \n",
    "    # load the image\n",
    "    img = Image.open(source)\n",
    "    \n",
    "    if rand_scale is not None:\n",
    "        s = np.random.uniform(rand_scale[0], rand_scale[1])\n",
    "        if resize_to is None:\n",
    "            resize_to = img.size\n",
    "        resize_to = (int(resize_to[0]/s), int(resize_to[1]/s))\n",
    "    \n",
    "    # augment if albumentation object was passed\n",
    "    img, boxes = _augment(img, boxes, tfm)\n",
    "    \n",
    "    w,h = img.size\n",
    "    w_ratio = resize_to[0]/w\n",
    "    h_ratio = resize_to[1]/h\n",
    "    # resize image and boxes\n",
    "    if resize_to is not None:\n",
    "        img = img.resize((resize_to[0],resize_to[1]))\n",
    "        boxes = [[int(b[0]*w_ratio), int(b[1]*h_ratio), int(b[2]*w_ratio), int(b[3]*h_ratio)] for b in boxes]\n",
    "    \n",
    "    # pick a box to crop around\n",
    "    boxchoice = np.random.randint(0, len(boxes))\n",
    "    b = boxes[boxchoice]\n",
    "    # choose a crop box that includes the centroid of the box\n",
    "    center_x = 0.5*(b[0]+b[2])\n",
    "    center_y = 0.5*(b[1]+b[3])\n",
    "    # ok, this merits some explanation: try to sample around the box without going outside\n",
    "    # the image:\n",
    "    min_w = max(center_x - cropsize[0],0)\n",
    "    max_w = min(center_x, resize_to[0]-cropsize[0])\n",
    "    if min_w < max_w:\n",
    "        w_offset = np.random.randint(min_w, max_w)\n",
    "    # if that won't work, pick a crop that goes outside the image\n",
    "    else:\n",
    "        w_offset = np.random.randint(center_x-cropsize[0], center_x)\n",
    "    # now repeat for vertical offset\n",
    "    min_h = max(center_y - cropsize[1],0)\n",
    "    max_h = min(center_y, resize_to[1]-cropsize[1])\n",
    "    if min_h < max_h:\n",
    "        h_offset = np.random.randint(min_h, max_h)\n",
    "    else:\n",
    "        h_offset = np.random.randint(center_y-cropsize[1], center_y)\n",
    "        \n",
    "    #w_offset = np.random.randint(max(center_x - cropsize[0],0), min(center_x, resize_to[0]-cropsize[0]))\n",
    "    #h_offset = np.random.randint(max(center_y - cropsize[1],0), min(center_y, resize_to[1]-cropsize[1]))\n",
    "    \n",
    "    crop_box = [w_offset, h_offset, w_offset+cropsize[0], h_offset+cropsize[1]]\n",
    "    # crop image and boxes\n",
    "    img_c = img.crop(crop_box)\n",
    "    outboxes, outlabels = _crop_boxes(boxes, crop_box, classes)\n",
    "    return img_c, outboxes, outlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc90552",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0623ed2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# [[2480, 1280, 2720, 1840], [640, 1840, 920, 2080]]\n",
    "i = 1\n",
    "img, boxes, labels = _random_crop(data[i][\"source\"], boxes=data[i][\"boxes\"], tfm=transform)\n",
    "img, boxes, labels = _crop_around_random_box(data[i][\"source\"], boxes=data[i][\"boxes\"], tfm=transform)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd08b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mosaic(sources, resize_each_to=None, outsize=None, minfrac=0.33, \n",
    "                  rand_scale=None, tfm=None):\n",
    "    \"\"\"\n",
    "    Construct a mosaic-augmented training example\n",
    "    \n",
    "    :sources: list of 4 dictionaries containing box/label info\n",
    "    :resize_each_to: if not None, a tuple of 2 numbers to resize image to before cropping\n",
    "    :outsize: dimensions of output image. if None, use resize_each_to\n",
    "    :minfrac: minimum fraction of a box's area to keep it\n",
    "    :rand_scale: None or a tuple of 2 numbers; randomly rescale images within that range\n",
    "    :tfm: albumentations transformation to apply\n",
    "    \"\"\"\n",
    "    np.random.shuffle(sources)\n",
    "    assert len(sources) == 4\n",
    "    if outsize is None:\n",
    "        outsize = resize_each_to\n",
    "    \n",
    "    # choose the x and y coordinates of the image splits\n",
    "    split_x = int(outsize[0]*np.random.uniform(minfrac, 1-minfrac))\n",
    "    split_y = int(outsize[1]*np.random.uniform(minfrac, 1-minfrac))\n",
    "    \n",
    "    # upper left\n",
    "    crop_size = (split_x, split_y)\n",
    "    s = sources[0]\n",
    "    img_ul, boxes_ul, labels_ul = _crop_around_random_box(s[\"source\"], boxes=s[\"boxes\"], \n",
    "                                                          classes=s[\"class\"], resize_to=resize_each_to, \n",
    "                                                          cropsize=crop_size, rand_scale=rand_scale,\n",
    "                                                          tfm=tfm)\n",
    "    # upper right\n",
    "    crop_size = (outsize[0] - split_x, split_y)\n",
    "    s = sources[1]\n",
    "    img_ur, boxes_ur, labels_ur = _crop_around_random_box(s[\"source\"], boxes=s[\"boxes\"], \n",
    "                                                          classes=s[\"class\"], resize_to=resize_each_to, \n",
    "                                                          cropsize=crop_size, rand_scale=rand_scale,\n",
    "                                                          tfm=tfm)\n",
    "    boxes_ur = [[b[0]+split_x, b[1], b[2]+split_x, b[3]] for b in boxes_ur]\n",
    "    \n",
    "    # lower left\n",
    "    crop_size = (split_x, outsize[1] - split_y)\n",
    "    s = sources[2]\n",
    "    img_ll, boxes_ll, labels_ll = _crop_around_random_box(s[\"source\"], boxes=s[\"boxes\"], \n",
    "                                                          classes=s[\"class\"], resize_to=resize_each_to, \n",
    "                                                          cropsize=crop_size, rand_scale=rand_scale,\n",
    "                                                          tfm=tfm)\n",
    "    boxes_ll = [[b[0], b[1]+split_y, b[2], b[3]+split_y] for b in boxes_ll]\n",
    "    \n",
    "    # lower right\n",
    "    crop_size = (outsize[0] - split_x, outsize[1]-split_y)\n",
    "    s = sources[3]\n",
    "    img_lr, boxes_lr, labels_lr = _crop_around_random_box(s[\"source\"], boxes=s[\"boxes\"], \n",
    "                                                          classes=s[\"class\"], resize_to=resize_each_to, \n",
    "                                                          cropsize=crop_size, rand_scale=rand_scale,\n",
    "                                                          tfm=tfm)\n",
    "    boxes_lr = [[b[0]+split_x, b[1]+split_y, b[2]+split_x, b[3]+split_y] for b in boxes_lr]\n",
    "    \n",
    "    boxes = boxes_ul + boxes_ur + boxes_ll + boxes_lr\n",
    "    labels = labels_ul + labels_ur + labels_ll + labels_lr\n",
    "    \n",
    "    img_arr = np.concatenate([\n",
    "        np.concatenate([np.array(img_ul), np.array(img_ur)], 1),\n",
    "        np.concatenate([np.array(img_ll), np.array(img_lr)], 1)\n",
    "    ], 0)\n",
    "    return Image.fromarray(img_arr), boxes, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1700cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, boxes, classes = build_mosaic([data[0], data[0], data[1], data[1]], rand_scale=(0.25, 2), outsize=(1000, 750),\n",
    "                                   tfm=transform)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9b164b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(min(len(boxes),9)):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(img.crop(boxes[i]))\n",
    "    plt.title(classes[i])\n",
    "    plt.axis(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7266ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bb90de",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, boxes, classes = build_mosaic([data[0], data[0], data[1], data[1]], rand_scale=(0.25, 2), \n",
    "                                   resize_each_to=(1000, 750),\n",
    "                                   tfm=transform)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecebdff6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d88d9e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d324a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
